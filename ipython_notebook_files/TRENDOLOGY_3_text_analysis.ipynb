{
 "metadata": {
  "name": "",
  "signature": "sha256:765e3613e50c585096713e853113629a412e5aa4c67d46c8d903b173082d49c3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hello.<br><br>\n",
      "This is the code that was used while writing the book:\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Trendology"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Building an Advantage through Data-Driven Real-Time Marketing "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "by Chris Kerns<br><br>\n",
      "You can find the book here: http://www.amazon.com/Trendology-Advantage-Data-Driven-Real-Time-Marketing/dp/1137479558\n",
      "<br>\n",
      "You can learn more about me and my latest data analysis here:\n",
      "http://chris-kerns.com\n",
      "<br>\n",
      "and you can find more code from the book here:\n",
      "http://github.com/chriskerns\n",
      "<br><br>\n",
      "Prereqs:<br>\n",
      "- This code assumes you have Python and a local MySQL database installed on your machine<br>\n",
      "- This code assumes you have a database table full of Tweets, as created in the \"TRENDOLOGY_1_Grab_Tweets\" script also located in this folder\n",
      "\n",
      "<br>\n",
      "My code isn't perfect, but it works. Have fun with it, make it better. <BR><BR>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# IMPORT A FEW THINGS\n",
      "import MySQLdb\n",
      "import datetime\n",
      "import time\n",
      "import nltk\n",
      "from nltk.corpus import stopwords\n",
      "from nltk.probability import FreqDist\n",
      "from nltk import bigrams, text\n",
      "from nltk.collocations import *\n",
      "import string\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "mydb = MySQLdb.connect(host='###ADD YOURS HERE###', user='###ADD YOURS HERE###', passwd='###ADD YOURS HERE###', db='###ADD YOURS HERE###')\n",
      "cursor = mydb.cursor()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SET DATABASE TABLE NAME\n",
      "\n",
      "varTableName = '##YOUR_DB_TABLE_NAME###'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# CREATE AN EXCLUDE LIST\n",
      "# THIS COULD BE FOR SCREENNAMES THAT POP UP A LOT OR JUST WORDS THAT ARE MESSING WITH YOUR ANALYSIS THAT YOU\n",
      "# DON'T CARE ABOUT. A GOOD THING TO HAVE FOR YOUR 2ND, 3RD RUN THROUGH THIS ANALYSIS AS YOU REFINE.\n",
      "\n",
      "varExclude = ['#remove me#']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#SAMPLE SQL TO GET ONLY TEXT FROM ORIGINAL BRAND TWEETS, NO RETWEETS OR @REPLIES\n",
      "varSQL = \"select tweettext from \" + varTableName + \" where tweettext not like 'RT%' and tweettext not like '@%'\"\n",
      "\n",
      "'''\n",
      "\n",
      "#OTHER SAMPLE SQL STATEMENTS:\n",
      "\n",
      "#SAMPLE SQL TO GET ONLY TEXT FROM RETWEETS\n",
      "varSQL = \"select tweettext from \" + varTableName + \" where tweettext like 'RT%'\"\n",
      "\n",
      "#SAMPLE SQL TO GET ONLY TEXT FROM @REPLIES\n",
      "varSQL = \"select tweettext from \" + varTableName + \" where tweettext like '@%'\"\n",
      "'''\n",
      "\n",
      "cursor.execute(varSQL)\n",
      "varReturn = cursor.fetchall()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#CREATE ONE BIG STRING FROM ALL TWEETS IN DB\n",
      "\n",
      "varMegaString = \"\"\n",
      "\n",
      "for item in varReturn:\n",
      "    varMegaString = varMegaString + \" \" + str(item[0])\n",
      "    \n",
      "varMegaString = varMegaString.translate(None, string.punctuation)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#TOKENIZE - SEPARATE OUT INDIVIDUAL WORDS\n",
      "#THIS STEP MAY TAKE A BIT OF TIME. GRAB A COFFEE. CALL AN OLD FRIEND.\n",
      "\n",
      "varMegaTokens = nltk.word_tokenize(varMegaString)\n",
      "\n",
      "#REMOVE ACTUAL MENTIONS OF 'RT' AND 'MT' - WE DON'T THOSE EVEN WHEN LOOKING AT RETWEETS\n",
      "#WE ALSO WANT TO GET RID OF URLS AND LINKS, UNLESS YOU CARE ABOUT THOSE\n",
      "\n",
      "varMegaTokens = [x for x in varMegaTokens if x != \"RT\"]\n",
      "varMegaTokens = [x for x in varMegaTokens if x != \"MT\"]\n",
      "varMegaTokens = [x for x in varMegaTokens if not x.startswith(\"http\")]\n",
      "varMegaTokens = [x for x in varMegaTokens if not x.startswith(\"tco\")]\n",
      "\n",
      "#REMOVE STOP WORDS - SMALL WORDS THAT YOU PROBABLY DON'T CARE ABOUT\n",
      "varMegaFiltered0 = [item for item in varMegaTokens if not item.lower() in stopwords.words('english')]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#FUNCTION FOR WORD FREQUENCY ON SINGLE TERMS - MOST FREQUENTLY USED WORDS FUNCTION\n",
      "\n",
      "def freqSingle(list):\n",
      "    global nouns\n",
      "    global adjectives\n",
      "    \n",
      "    #fig, axs = plt.subplots(1,2)\n",
      "\n",
      "    varPOS = [nltk.pos_tag(list)] \n",
      "    \n",
      "    ##################################################\n",
      "    #ALL LANGUAGE - FREQUENCY\n",
      "    varAll = FreqDist(list)\n",
      "    \n",
      "    ##USE THIS TO PRINT THE TOP WORDS\n",
      "    print \"TOP TERMS\"\n",
      "    varAll_common = varAll.most_common(25)\n",
      "    print varAll_common\n",
      "    print \"\"\n",
      "    \n",
      "    #PLOT TOP TERMS\n",
      "    #varAll.plot(25, cumulative=False, title='All Language')\n",
      "    #plt.show()\n",
      "    \n",
      "    ##################################################\n",
      "    #NOUNS - FREQUENCY\n",
      "    nouns = []\n",
      "    for word,pos in varPOS[0]:\n",
      "        if pos in ['NN', 'NNP']:\n",
      "            nouns.append(word)\n",
      "    varNouns = FreqDist(nouns)\n",
      "\n",
      "    ##USE THIS TO PRINT THE TOP NOUNS\n",
      "    print \"TOP NOUNS\"\n",
      "    varNouns_common = varNouns.most_common(25)\n",
      "    print varNouns_common\n",
      "    print \"\"\n",
      "    \n",
      "    #PLOT TOP NOUNS\n",
      "    #varNouns.plot(25, cumulative=False, title='Nouns')\n",
      "    #plt.show()\n",
      "    \n",
      "    ##################################################\n",
      "    #ADJECTIVES - FREQUENCY\n",
      "    adjectives = []\n",
      "    for word,pos in varPOS[0]:\n",
      "        if pos in ['JJ', 'JJR', 'JJS']:\n",
      "            adjectives.append(word)\n",
      "    varAdjectives = FreqDist(adjectives)\n",
      "    \n",
      "    \n",
      "    ##USE THIS TO PRINT THE TOP ADJECTIVES\n",
      "    print \"TOP ADJECTIVES\"\n",
      "    varAdjectives_common = varAdjectives.most_common(25)\n",
      "    print varAdjectives_common\n",
      "    print \"\"\n",
      "    \n",
      "    #PLOT TOP ADJECTIVES\n",
      "    #varAdjectives.plot(25, cumulative=False, title='Adjectives')\n",
      "    #plt.show()\n",
      "    \n",
      "    #YOU CAN ADD OTHER PARTS OF SPEECH. VISIT WWW.NLTK.ORG FOR DOCUMENTATION\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#CALL THE SINGLE TERM FREQUENCY FUNCTION\n",
      "\n",
      "freqSingle(varMegaFiltered0)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TOP TERMS\n",
        "[('social', 659), ('marketing', 199), ('SFSummit', 196), ('new', 168), ('brands', 155), ('media', 145), ('data', 143), ('Social', 139), ('via', 117), ('brand', 110), ('amp', 103), ('great', 99), ('Twitter', 94), ('worlds', 89), ('measure', 85), ('team', 77), ('like', 76), ('largest', 69), ('Spredfast', 68), ('time', 67), ('Facebook', 65), ('content', 65), ('realtime', 63), ('Google', 62), ('next', 61)]\n",
        "\n",
        "TOP NOUNS\n",
        "[('SFSummit', 191), ('marketing', 185), ('Social', 125), ('brand', 102), ('Twitter', 94), ('amp', 89), ('measure', 81), ('team', 77), ('Spredfast', 67), ('Facebook', 65), ('time', 65), ('content', 62), ('Google', 62), ('New', 60), ('realtime', 56), ('Austin', 56), ('business', 52), ('program', 49), ('RTM', 48), ('Learn', 47), ('way', 44), ('Great', 44), ('success', 44), ('TV', 44), ('audience', 43)]\n",
        "\n",
        "TOP ADJECTIVES\n",
        "[('social', 653), ('new', 168), ('largest', 69), ('great', 61), ('best', 45), ('top', 35), ('next', 31), ('last', 29), ('big', 27), ('good', 25), ('visual', 23), ('old', 20), ('key', 15), ('organic', 14), ('Social', 14), ('biggest', 14), ('many', 13), ('favorite', 13), ('high', 12), ('global', 11), ('4Music', 11), ('professional', 11), ('latest', 11), ('free', 10), ('first', 10)]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#BIGRAMS - TERMS FREQUENTLY OCCURRING TOGETHER (COMMON PHRASES) FUNCTION\n",
      "\n",
      "def freqBigram(list):\n",
      "    varBigramsFreq = nltk.FreqDist(nltk.bigrams(list))\n",
      "    \n",
      "    ##USE THIS TO PRINT THE TOP ADJECTIVES\n",
      "    print \"TOP TWO WORD PHRASES\"\n",
      "    varBigrams_common = varBigramsFreq.most_common(25)\n",
      "    print varBigrams_common\n",
      "    print \"\"\n",
      "    \n",
      "    #varBigramsFreq.plot(25, cumulative=False, title=\"Bigrams\")\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#CALL THE BIGRAM FUNCTION\n",
      "\n",
      "freqBigram(varMegaFiltered0)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TOP TWO WORD PHRASES\n",
        "[(('social', 'media'), 102), (('worlds', 'largest'), 66), (('social', 'marketing'), 53), (('realtime', 'marketing'), 41), (('social', 'program'), 37), (('largest', 'brands'), 35), (('social', 'data'), 31), (('social', 'programs'), 21), (('programs', 'worlds'), 16), (('social', 'business'), 15), (('largest', 'companies'), 15), (('social', 'sponsorship'), 15), (('paid', 'owned'), 15), (('owned', 'earned'), 15), (('social', 'success'), 15), (('next', 'level'), 15), (('Social', 'Business'), 14), (('Social', 'Media'), 14), (('social', 'team'), 14), (('visual', 'content'), 13), (('customer', 'care'), 13), (('worlds', 'leading'), 11), (('marketing', 'programs'), 11), (('last', 'night'), 11), (('Weve', 'got'), 11)]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# THAT'S IT. PLAY AROUND WITH DIFFERENT PARTS OF SPEECH, AND DIFFERENT SQL QUERIES\n",
      "# WHICH WILL GET YOU DIFFERENT SLICES OF TWEET TEXT. \n",
      "# EX: PULL ONLY THE TOP PERFORMING TWEETS VIA YOUR SQL QUERY \n",
      "# AND SEE HOW THOSE DIFFER FROM LOW PERFORMERS.\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you're having problems with the code or just want to chat, ping me at chris@chris-kerns.com\n",
      "\n",
      "Happy coding! Go make something awesome.\n",
      "\n",
      "/chris"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}